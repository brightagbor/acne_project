{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1599ec5f-f01c-4466-905c-9e6db29a27ac",
   "metadata": {},
   "source": [
    "### Acne Detection and Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc4aeb3-4ef2-46fa-8ae2-677f31ec0b84",
   "metadata": {},
   "source": [
    "### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "546284f5-78e3-471d-a644-c2829d271a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 03:13:04.188506: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-01 03:13:04.249196: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-01 03:13:04.330928: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-01 03:13:04.413182: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-01 03:13:04.428569: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-01 03:13:04.559074: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-01 03:13:05.512587: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09846e53-5515-4db0-85a2-0cc8dec5b203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#help(EarlyStopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f872811d-b6c2-4813-af21-d8875692d3ad",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "**Augment the training data to create more diverse training examples, improving model robustness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5546517f-e529-45e1-8a5a-eef473fc3871",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fdecc8-9e37-4f8c-b81c-2ca99e43ac60",
   "metadata": {},
   "source": [
    "### No augmentation for validation and test data; just rescale the pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7aad40c-fb67-4fe3-a06d-2681a1fb474f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1f83aa-6e2a-40ce-9490-b0dcf0c31836",
   "metadata": {},
   "source": [
    "### Load and preprocess the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b756553-9b40-4d57-aa50-db15dab92e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1646 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_image_directory = \"dataset/training/\"\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_image_directory,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\", # Binary Classification (acne or no acne)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6571a50-e0f0-4016-8c7d-1d5035ab2011",
   "metadata": {},
   "source": [
    "### Load and preprocess the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a2a25d3-69c2-43db-90c5-200e8e4260ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_image_directory = \"dataset/validation/\"\n",
    "\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory=validation_image_directory,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\", # Binary Classification (acne or no acne)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb7d45e-01b9-4d0f-b0a4-b4cbf2a08668",
   "metadata": {},
   "source": [
    "### Load and preprocess the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d47bb633-f9ee-4b36-9cde-6d89e6286bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 112 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_image_directory = \"dataset/testing/\"\n",
    "\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    directory=validation_image_directory,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode=\"binary\", # Binary Classification (acne or no acne)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e8267-0588-42f0-b5cd-1e3581e433f6",
   "metadata": {},
   "source": [
    "### Load the pre-trained VGG16 model, excluding  the top (fully connected) layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c85f145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(input_shape=(150, 150, 3), include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe581ee-17c5-4a93-aa8d-0c1350defacc",
   "metadata": {},
   "source": [
    "### Freeze the base model's layers to prevent them from being updated during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd4899fe-2f32-4a2c-b1ef-f67132143ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba5617c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Functional name=vgg16, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd29ad32-5e4e-463b-82e1-9a691a09218f",
   "metadata": {},
   "source": [
    "### Add custom layers on top of the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c41ecb1b-927f-4965-aafb-8d28adfe90cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(base_model.output)\n",
    "x = Dense(512, activation = \"relu\")(x)\n",
    "output = Dense(units=1, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad14d43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 512), dtype=float32, sparse=False, name=keras_tensor_23>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df799e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_24>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9645c473-d7ee-44c4-b6af-5b54fec29f70",
   "metadata": {},
   "source": [
    "### Create the complete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54570ee2-3872-4a63-a6fb-a8f8ad13f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fb61353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Functional name=functional, built=True>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1b3345-13c3-4e44-a64f-50ecc2b04c15",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77202b49-94bf-453a-bdde-eb891074f372",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a545dd",
   "metadata": {},
   "source": [
    "### Use early stopping to prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cac2996-5a06-4374-a8dc-2eb5c0e1eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c9976a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.early_stopping.EarlyStopping at 0x7f9254b86f10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e47bcd-b841-444f-81c9-6106bd75cc51",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3053d110-bfb2-46c7-8e44-7c001af75f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agbor/anaconda3/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 2s/step - accuracy: 0.6761 - loss: 0.8162 - val_accuracy: 0.8125 - val_loss: 0.3842\n",
      "Epoch 2/5\n",
      "\u001b[1m 1/51\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:53\u001b[0m 2s/step - accuracy: 0.8125 - loss: 0.2898"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 03:23:35.068623: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/home/agbor/anaconda3/lib/python3.11/contextlib.py:155: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.8125 - loss: 0.2898 - val_accuracy: 0.8125 - val_loss: 0.3669\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 03:23:36.340155: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 3s/step - accuracy: 0.8814 - loss: 0.3138 - val_accuracy: 0.9271 - val_loss: 0.2361\n",
      "Epoch 4/5\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - accuracy: 0.7812 - loss: 0.5817 - val_accuracy: 0.6250 - val_loss: 1.0299\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 03:25:50.462930: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 3s/step - accuracy: 0.8905 - loss: 0.2645 - val_accuracy: 0.8438 - val_loss: 0.2933\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples //train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=5,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0c968e4-6e15-49d4-bd34-19dbb0ca5adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step - accuracy: 0.8698 - loss: 0.2907\n",
      "Test Accuracy: 0.8646\n"
     ]
    }
   ],
   "source": [
    "### Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5276c23a",
   "metadata": {},
   "source": [
    "### Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe1fc811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the image and resize it to 64x64\n",
    "image_path = \"dataset/testing/acne/acne-7_jpeg.rf.34ee37b930f592f787bb8d1bf6b37d30.jpg\"\n",
    "\n",
    "test_image = image.load_img(image_path, target_size=(150, 150))\n",
    "test_image = image.img_to_array(test_image)\n",
    "\n",
    "# Expand dimensions to add the batch size\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "# Predicting the result\n",
    "result = model.predict(test_image)\n",
    "\n",
    "train_generator.class_indices\n",
    "\n",
    "if result[0][0] == 1:\n",
    "    prediction = \"Acne\"\n",
    "else:\n",
    "    prediction = \"Non Acne\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f8689d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non Acne\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfd9922",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
